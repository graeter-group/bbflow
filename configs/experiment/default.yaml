debug: False
use_wandb: True
use_tqdm: False

seed: 123
num_devices: 2
warm_start: null
warm_start_cfg_override: True
use_swa: False
first_val_epoch: 0
reset_epoch: False

batch_ot:
  enabled: True
  cost: kabsch
  noise_per_sample: 1
  # permute: False
training:
  min_plddt_mask: null
  loss: se3_vf_loss
  bb_atom_scale: 0.1
  trans_scale: 0.1
  translation_loss_weight: 2.0
  t_normalize_clip: 0.9
  rotation_loss_weights: 1.0
  aux_loss_weight: 1.0
  aux_loss_t_pass: 0.75
  t_bins: 4
  ca_distmat_loss_weight: 0.0
wandb:
  name: baseline
  project: bbflow
  save_dir: outputs/
  # save_code: True
  tags: []
optimizer:
  lr: 0.0001
reset_optimizer_on_load: False
warmup_lr: False
warmup_lr_factor: 0.01
trainer:
  overfit_batches: 0
  min_epochs: 1 # prevents early stopping
  max_epochs: 250
  accelerator: gpu
  log_every_n_steps: 1
  deterministic: False
  strategy: ddp
  check_val_every_n_epoch: 1
  default_root_dir: outputs/
  accumulate_grad_batches: 1
checkpointer:
  dirpath: outputs/ckpt/${experiment.wandb.project}/${experiment.wandb.name}/${now:%Y-%m-%d}_${now:%H-%M-%S}
  save_last: True
  save_on_train_epoch_end: True
  filename: "epoch:{epoch:03d}"
  every_n_epochs: 1
  save_top_k: -1
  auto_insert_metric_name: False
checkpointer2: null # TODO: maybe remove/change
  # dirpath: outputs/ckpt/${experiment.wandb.project}/${experiment.wandb.name}/${now:%Y-%m-%d}_${now:%H-%M-%S}
  # save_last: False
  # filename: "sec_dev:{sec_deviation:.2f}-epoch:{epoch:03d}"
  # save_top_k: 10
  # monitor: valid/sec_deviation
  # mode: min
  # every_n_epochs: 1
  # first_epoch: ${experiment.first_val_epoch}
  # auto_insert_metric_name: False
profiler:
  enabled: False
  modules: null # Optional list of modules which should be profiled
  profile:
    use_cuda: True
    with_stack: False
  stats:
    group_by_stack_n: 0
    group_by_input_shapes: False
    prefixes: ['layer_0::', 'layer_1::']
    sort_by: 'cpu_time_total'
